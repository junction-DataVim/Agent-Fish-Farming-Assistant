{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03cd307",
   "metadata": {},
   "source": [
    "# Fish Farming Assistant Agent Documentation\n",
    "\n",
    "## Overview\n",
    "The **Fish Farming Assistant** is an AI-powered agent designed to help manage and optimize aquaculture operations. It leverages a combination of database queries and advanced AI models (such as Groq ) to provide actionable insights, monitor pond health, analyze sensor data, and alert users to potential issues.\n",
    "\n",
    "## Key Features\n",
    "- **Sensor Data Analysis:** Query and analyze real-time and historical sensor readings (temperature, pH, dissolved oxygen, turbidity, etc.).\n",
    "- **Pond Status Monitoring:** Track fish growth, survival rate, and health status for each pond.\n",
    "- **Alert Management:** Review and analyze alerts for critical events (e.g., disease outbreaks, low oxygen levels).\n",
    "- **Comprehensive Summaries:** Generate detailed summaries for any pond, including recent alerts and available sensors.\n",
    "- **AI-Powered Insights:** Use Groq or OpenAI models to answer complex questions, provide recommendations, and explain technical data in user-friendly terms.\n",
    "- **Fallback to Direct Analysis:** If no API key is set, the agent can still provide full database-driven analysis and reporting.\n",
    "\n",
    "## Usage\n",
    "1. **Setup:**\n",
    "   - Install required dependencies (see `requirements.txt`).\n",
    "   - Ensure the fish farming database (`fish_farming_timeseries.db`) is available and populated.\n",
    "   - Set your Groq or OpenAI API key as an environment variable for AI-powered features.\n",
    "2. **Available Tools:**\n",
    "   - `sensor_tool`: Query sensor readings.\n",
    "   - `pond_tool`: Query pond status.\n",
    "   - `alert_tool`: Query alerts.\n",
    "   - `summary_tool`: Get pond summary.\n",
    "   - `list_tool`: List all available ponds.\n",
    "3. **Agent Capabilities:**\n",
    "   - Ask the agent questions about pond health, water quality, recent alerts, and receive actionable recommendations.\n",
    "   - Use the agent for both manual data analysis and AI-enhanced insights.\n",
    "\n",
    "## Example Questions\n",
    "- \"What is the current health status of TilapiaPond_001?\"\n",
    "- \"Show recent sensor readings for all ponds.\"\n",
    "- \"Are there any critical alerts in the last 24 hours?\"\n",
    "- \"Recommend actions to improve survival rate.\"\n",
    "\n",
    "## Notes\n",
    "- The agent is extensible: you can add new tools or connect to other AI models as needed.\n",
    "- If the AI API key is not set, the agent will automatically fall back to direct database analysis.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0425c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools module contents: ['Function', 'FunctionCall', 'Toolkit', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'decorator', 'function', 'tool', 'toolkit']\n",
      "Cannot import Tool from base: No module named 'agno.tools.base'\n",
      "Cannot import FunctionTool: cannot import name 'FunctionTool' from 'agno.tools.function' (c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\agno\\tools\\function.py)\n",
      "Models available: ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'base', 'groq', 'message', 'response']\n"
     ]
    }
   ],
   "source": [
    "# Let's explore the agno structure properly\n",
    "import agno\n",
    "from agno.agent import Agent\n",
    "\n",
    "# Check what's in tools\n",
    "try:\n",
    "    import agno.tools\n",
    "    print(\"Tools module contents:\", dir(agno.tools))\n",
    "except Exception as e:\n",
    "    print(f\"Tools module error: {e}\")\n",
    "\n",
    "# Try different imports\n",
    "try:\n",
    "    from agno.tools.base import Tool\n",
    "    print(\"Tool from base imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Cannot import Tool from base: {e}\")\n",
    "\n",
    "try:\n",
    "    from agno.tools.function import FunctionTool\n",
    "    print(\"FunctionTool imported successfully\")  \n",
    "except ImportError as e:\n",
    "    print(f\"Cannot import FunctionTool: {e}\")\n",
    "\n",
    "# Check what models are available\n",
    "try:\n",
    "    import agno.models\n",
    "    print(\"Models available:\", dir(agno.models))\n",
    "except Exception as e:\n",
    "    print(f\"Models error: {e}\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d85d76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish farming database functions created successfully!\n",
      "Available functions:\n",
      "- query_sensor_readings()\n",
      "- query_pond_status()\n",
      "- query_alerts()\n",
      "- get_pond_summary()\n",
      "- list_all_ponds()\n"
     ]
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.tools import Function\n",
    "\n",
    "# Fish Farming Database Functions\n",
    "def query_sensor_readings(pond_id: str = None, sensor_type: str = None, hours_back: int = 24, limit: int = 50) -> str:\n",
    "    \"\"\"\n",
    "    Query sensor readings from the fish farming database.\n",
    "    \n",
    "    Args:\n",
    "        pond_id: ID of the pond to query (optional)\n",
    "        sensor_type: Type of sensor (temperature, ph, oxygen, etc.) (optional)\n",
    "        hours_back: Number of hours back to query (default 24)\n",
    "        limit: Maximum number of records to return (default 50)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with sensor readings\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(\"fish_farming_timeseries.db\")\n",
    "        \n",
    "        # Calculate timestamp for hours_back\n",
    "        now = int(datetime.now().timestamp())\n",
    "        start_time = now - (hours_back * 3600)\n",
    "        \n",
    "        query = \"SELECT * FROM sensor_readings WHERE timestamp >= ?\"\n",
    "        params = [start_time]\n",
    "        \n",
    "        if pond_id:\n",
    "            query += \" AND pond_id = ?\"\n",
    "            params.append(pond_id)\n",
    "        if sensor_type:\n",
    "            query += \" AND sensor_type = ?\"\n",
    "            params.append(sensor_type)\n",
    "            \n",
    "        query += \" ORDER BY timestamp DESC LIMIT ?\"\n",
    "        params.append(limit)\n",
    "        \n",
    "        cursor = conn.execute(query, params)\n",
    "        columns = [description[0] for description in cursor.description]\n",
    "        results = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "        conn.close()\n",
    "        \n",
    "        # Convert timestamps to readable format\n",
    "        for result in results:\n",
    "            result['readable_time'] = datetime.fromtimestamp(result['timestamp']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        return json.dumps(results, indent=2)\n",
    "    except Exception as e:\n",
    "        return f\"Error querying sensor readings: {str(e)}\"\n",
    "\n",
    "def query_pond_status(pond_id: str = None, hours_back: int = 24, limit: int = 20) -> str:\n",
    "    \"\"\"\n",
    "    Query pond status from the fish farming database.\n",
    "    \n",
    "    Args:\n",
    "        pond_id: ID of the pond to query (optional)\n",
    "        hours_back: Number of hours back to query (default 24)\n",
    "        limit: Maximum number of records to return (default 20)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with pond status data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(\"fish_farming_timeseries.db\")\n",
    "        \n",
    "        # Calculate timestamp for hours_back\n",
    "        now = int(datetime.now().timestamp())\n",
    "        start_time = now - (hours_back * 3600)\n",
    "        \n",
    "        query = \"SELECT * FROM pond_status WHERE timestamp >= ?\"\n",
    "        params = [start_time]\n",
    "        \n",
    "        if pond_id:\n",
    "            query += \" AND pond_id = ?\"\n",
    "            params.append(pond_id)\n",
    "            \n",
    "        query += \" ORDER BY timestamp DESC LIMIT ?\"\n",
    "        params.append(limit)\n",
    "        \n",
    "        cursor = conn.execute(query, params)\n",
    "        columns = [description[0] for description in cursor.description]\n",
    "        results = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "        conn.close()\n",
    "        \n",
    "        # Convert timestamps to readable format\n",
    "        for result in results:\n",
    "            result['readable_time'] = datetime.fromtimestamp(result['timestamp']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        return json.dumps(results, indent=2)\n",
    "    except Exception as e:\n",
    "        return f\"Error querying pond status: {str(e)}\"\n",
    "\n",
    "def query_alerts(pond_id: str = None, severity: str = None, resolved: bool = None, hours_back: int = 168, limit: int = 30) -> str:\n",
    "    \"\"\"\n",
    "    Query alerts from the fish farming database.\n",
    "    \n",
    "    Args:\n",
    "        pond_id: ID of the pond to query (optional)\n",
    "        severity: Alert severity (critical, warning, info) (optional)\n",
    "        resolved: Whether alert is resolved (True/False) (optional)\n",
    "        hours_back: Number of hours back to query (default 168 = 1 week)\n",
    "        limit: Maximum number of records to return (default 30)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with alerts data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(\"fish_farming_timeseries.db\")\n",
    "        \n",
    "        # Calculate timestamp for hours_back\n",
    "        now = int(datetime.now().timestamp())\n",
    "        start_time = now - (hours_back * 3600)\n",
    "        \n",
    "        query = \"SELECT * FROM alerts WHERE timestamp >= ?\"\n",
    "        params = [start_time]\n",
    "        \n",
    "        if pond_id:\n",
    "            query += \" AND pond_id = ?\"\n",
    "            params.append(pond_id)\n",
    "        if severity:\n",
    "            query += \" AND severity = ?\"\n",
    "            params.append(severity)\n",
    "        if resolved is not None:\n",
    "            query += \" AND resolved = ?\"\n",
    "            params.append(resolved)\n",
    "            \n",
    "        query += \" ORDER BY timestamp DESC LIMIT ?\"\n",
    "        params.append(limit)\n",
    "        \n",
    "        cursor = conn.execute(query, params)\n",
    "        columns = [description[0] for description in cursor.description]\n",
    "        results = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "        conn.close()\n",
    "        \n",
    "        # Convert timestamps to readable format\n",
    "        for result in results:\n",
    "            result['readable_time'] = datetime.fromtimestamp(result['timestamp']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            if result['resolved_at']:\n",
    "                result['resolved_time'] = datetime.fromtimestamp(result['resolved_at']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        return json.dumps(results, indent=2)\n",
    "    except Exception as e:\n",
    "        return f\"Error querying alerts: {str(e)}\"\n",
    "\n",
    "def get_pond_summary(pond_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Get a comprehensive summary for a specific pond.\n",
    "    \n",
    "    Args:\n",
    "        pond_id: ID of the pond to summarize\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with pond summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(\"fish_farming_timeseries.db\")\n",
    "        \n",
    "        # Latest pond status\n",
    "        cursor = conn.execute(\n",
    "            \"SELECT * FROM pond_status WHERE pond_id = ? ORDER BY timestamp DESC LIMIT 1\",\n",
    "            (pond_id,)\n",
    "        )\n",
    "        latest_status = cursor.fetchone()\n",
    "        if latest_status:\n",
    "            columns = [description[0] for description in cursor.description]\n",
    "            latest_status = dict(zip(columns, latest_status))\n",
    "            latest_status['readable_time'] = datetime.fromtimestamp(latest_status['timestamp']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Count of recent alerts (last 24 hours)\n",
    "        now = int(datetime.now().timestamp())\n",
    "        day_ago = now - 86400\n",
    "        alert_count = conn.execute(\n",
    "            \"SELECT COUNT(*) FROM alerts WHERE pond_id = ? AND timestamp >= ?\",\n",
    "            (pond_id, day_ago)\n",
    "        ).fetchone()[0]\n",
    "        \n",
    "        # Available sensor types\n",
    "        sensor_types = conn.execute(\n",
    "            \"SELECT DISTINCT sensor_type FROM sensor_readings WHERE pond_id = ?\",\n",
    "            (pond_id,)\n",
    "        ).fetchall()\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        summary = {\n",
    "            \"pond_id\": pond_id,\n",
    "            \"latest_status\": latest_status,\n",
    "            \"recent_alerts_count_24h\": alert_count,\n",
    "            \"available_sensors\": [row[0] for row in sensor_types]\n",
    "        }\n",
    "        \n",
    "        return json.dumps(summary, indent=2)\n",
    "    except Exception as e:\n",
    "        return f\"Error getting pond summary: {str(e)}\"\n",
    "\n",
    "def list_all_ponds() -> str:\n",
    "    \"\"\"\n",
    "    List all pond IDs available in the database.\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with list of pond IDs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(\"fish_farming_timeseries.db\")\n",
    "        \n",
    "        pond_ids = conn.execute(\n",
    "            \"SELECT DISTINCT pond_id FROM pond_status ORDER BY pond_id\"\n",
    "        ).fetchall()\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        result = {\n",
    "            \"pond_ids\": [row[0] for row in pond_ids],\n",
    "            \"total_count\": len(pond_ids)\n",
    "        }\n",
    "        \n",
    "        return json.dumps(result, indent=2)\n",
    "    except Exception as e:\n",
    "        return f\"Error listing ponds: {str(e)}\"\n",
    "\n",
    "print(\"Fish farming database functions created successfully!\")\n",
    "print(\"Available functions:\")\n",
    "print(\"- query_sensor_readings()\")\n",
    "print(\"- query_pond_status()\")\n",
    "print(\"- query_alerts()\")\n",
    "print(\"- get_pond_summary()\")\n",
    "print(\"- list_all_ponds()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5653e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools created successfully!\n",
      "Fish Farming Agent created successfully!\n",
      "\\nAgent capabilities:\n",
      "- Query sensor readings (temperature, pH, oxygen, etc.)\n",
      "- Check pond status and health metrics\n",
      "- Review alerts and their severity\n",
      "- Generate pond summaries\n",
      "- List all available ponds\n",
      "\\nYou can now ask questions about your fish farming operation!\n"
     ]
    }
   ],
   "source": [
    "# Create Function tools properly with names\n",
    "sensor_tool = Function(\n",
    "    name=\"query_sensor_readings\",\n",
    "    function=query_sensor_readings\n",
    ")\n",
    "pond_tool = Function(\n",
    "    name=\"query_pond_status\", \n",
    "    function=query_pond_status\n",
    ")\n",
    "alert_tool = Function(\n",
    "    name=\"query_alerts\",\n",
    "    function=query_alerts\n",
    ")\n",
    "summary_tool = Function(\n",
    "    name=\"get_pond_summary\",\n",
    "    function=get_pond_summary\n",
    ")\n",
    "list_tool = Function(\n",
    "    name=\"list_all_ponds\",\n",
    "    function=list_all_ponds\n",
    ")\n",
    "\n",
    "print(\"Tools created successfully!\")\n",
    "\n",
    "# Create the Fish Farming Agent\n",
    "fish_farming_agent = Agent(\n",
    "    name=\"Fish Farming Assistant\",\n",
    "    description=\"An AI assistant specialized in fish farming management that can query databases to provide insights about pond conditions, sensor readings, and alerts.\",\n",
    "    instructions=[\n",
    "        \"You are a fish farming expert AI assistant.\",\n",
    "        \"You have access to a comprehensive fish farming database with sensor readings, pond status, and alerts.\",\n",
    "        \"Always provide detailed, actionable insights based on the data.\",\n",
    "        \"When analyzing data, look for patterns, anomalies, and potential issues.\",\n",
    "        \"Explain technical readings in terms that fish farmers can understand.\",\n",
    "        \"Suggest corrective actions when problems are detected.\",\n",
    "        \"Always consider the health and welfare of the fish in your recommendations.\"\n",
    "    ],\n",
    "    tools=[sensor_tool, pond_tool, alert_tool, summary_tool, list_tool],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "print(\"Fish Farming Agent created successfully!\")\n",
    "print(\"\\\\nAgent capabilities:\")\n",
    "print(\"- Query sensor readings (temperature, pH, oxygen, etc.)\")\n",
    "print(\"- Check pond status and health metrics\") \n",
    "print(\"- Review alerts and their severity\")\n",
    "print(\"- Generate pond summaries\")\n",
    "print(\"- List all available ponds\")\n",
    "print(\"\\\\nYou can now ask questions about your fish farming operation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f1c31e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset has 4383 rows and 28 columns\n",
      "Date range: 2024-01-01 00:00:00 to 2024-07-01 14:00:00\n",
      "\n",
      "Sample dataset has 50 rows\n",
      "Sample date range: 2024-01-05 13:00:00 to 2024-06-30 12:00:00\n",
      "\n",
      "First 10 rows of the sample:\n",
      "              Datetime    Month  Average Fish Weight (g)  Survival Rate (%)  \\\n",
      "0  2024-01-05 13:00:00  January               275.820000          95.270000   \n",
      "1  2024-01-06 00:00:00  January               275.820000          95.270000   \n",
      "2  2024-01-07 05:00:00  January               275.820000          95.270000   \n",
      "3  2024-01-07 07:00:00  January               275.820000          95.270000   \n",
      "4  2024-01-08 11:00:00  January               275.820000          95.270000   \n",
      "5  2024-01-25 13:00:00  January               275.820000          95.270000   \n",
      "6  2024-01-25 18:00:00  January               275.820000          95.270000   \n",
      "7  2024-01-25 20:00:00  January               275.820000          95.270000   \n",
      "8  2024-01-25 23:00:00  January               275.820000          95.270000   \n",
      "9  2024-01-28 22:00:00  January               276.245934          94.855275   \n",
      "\n",
      "   Disease Occurrence (Cases)  Temperature (Â°C)  Dissolved Oxygen (mg/L)  \\\n",
      "0                    2.000000         27.470000                 6.340000   \n",
      "1                    2.000000         27.470000                 6.340000   \n",
      "2                    2.000000         27.470000                 6.340000   \n",
      "3                    2.000000         27.470000                 6.340000   \n",
      "4                    2.000000         27.470000                 6.340000   \n",
      "5                    2.000000         27.470000                 6.340000   \n",
      "6                    2.000000         27.470000                 6.340000   \n",
      "7                    2.000000         27.470000                 6.340000   \n",
      "8                    2.000000         27.470000                 6.340000   \n",
      "9                    1.813187         27.288791                 6.364286   \n",
      "\n",
      "        pH  Turbidity (NTU)  Month_Num  ...        day      hour  \\\n",
      "0  7.98000         3.300000   1.000000  ...   5.421053  2.894737   \n",
      "1  7.98000         3.300000   1.000000  ...   6.000000  0.000000   \n",
      "2  7.98000         3.300000   1.000000  ...   7.000000  5.000000   \n",
      "3  7.98000         3.300000   1.000000  ...   7.105263  4.473684   \n",
      "4  7.98000         3.300000   1.000000  ...   8.315789  3.421053   \n",
      "5  7.98000         3.300000   1.000000  ...  25.421053  2.894737   \n",
      "6  7.98000         3.300000   1.000000  ...  25.684211  1.578947   \n",
      "7  7.98000         3.300000   1.000000  ...  25.789474  1.052632   \n",
      "8  7.98000         3.300000   1.000000  ...  25.947368  0.263158   \n",
      "9  7.86044         3.204725   1.186813  ...  22.956044  4.065934   \n",
      "\n",
      "   oxigeno_scaled        ph  turbidez  Oxygenation Automatic  \\\n",
      "0        8.277904  0.401163  0.037005                     No   \n",
      "1        8.116849  0.388776  0.026251                    Yes   \n",
      "2        8.209044  0.401639 -0.007360                     No   \n",
      "3        8.217327  0.400622 -0.006235                     No   \n",
      "4        8.505729  0.394733 -0.007127                     No   \n",
      "5        7.949265  0.633841 -0.012861                     No   \n",
      "6        8.005083  0.793207 -0.026772                    Yes   \n",
      "7        8.027410  0.856954 -0.032337                    Yes   \n",
      "8        8.060900  0.952573 -0.040684                     No   \n",
      "9        8.313406  0.389414  0.011968                    Yes   \n",
      "\n",
      "   Corrective Measures  Thermal Risk Index  Low Oxygen Alert  Health Status  \n",
      "0                   No              Normal              Safe         Stable  \n",
      "1                   No              Normal              Safe         Stable  \n",
      "2                   No              Normal              Safe         Stable  \n",
      "3                   No              Normal              Safe         Stable  \n",
      "4                   No              Normal              Safe         Stable  \n",
      "5                   No              Normal              Safe         Stable  \n",
      "6                   No              Normal              Safe         Stable  \n",
      "7                   No              Normal              Safe         Stable  \n",
      "8                   No              Normal              Safe         Stable  \n",
      "9                   No              Normal              Safe         Stable  \n",
      "\n",
      "[10 rows x 28 columns]\n",
      "\n",
      "Sample saved to 'sample_data_50_lines.csv'\n",
      "\n",
      "Columns in the dataset (28):\n",
      " 1. Datetime\n",
      " 2. Month\n",
      " 3. Average Fish Weight (g)\n",
      " 4. Survival Rate (%)\n",
      " 5. Disease Occurrence (Cases)\n",
      " 6. Temperature (Â°C)\n",
      " 7. Dissolved Oxygen (mg/L)\n",
      " 8. pH\n",
      " 9. Turbidity (NTU)\n",
      "10. Month_Num\n",
      "11. month_x\n",
      "12. Oxygenation Interventions\n",
      "13. Corrective Interventions\n",
      "14. Average Temperature (Â°C)\n",
      "15. High Temperature (Â°C)\n",
      "16. Low Temperature (Â°C)\n",
      "17. Precipitation (inches)\n",
      "18. month_y\n",
      "19. day\n",
      "20. hour\n",
      "21. oxigeno_scaled\n",
      "22. ph\n",
      "23. turbidez\n",
      "24. Oxygenation Automatic\n",
      "25. Corrective Measures\n",
      "26. Thermal Risk Index\n",
      "27. Low Oxygen Alert\n",
      "28. Health Status\n"
     ]
    }
   ],
   "source": [
    "# Create a sample of 50 lines from the CSV data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the full CSV file\n",
    "df = pd.read_csv('Data_Model_IoTMLCQ_2024.csv')\n",
    "\n",
    "print(f\"Original dataset has {len(df)} rows and {len(df.columns)} columns\")\n",
    "print(f\"Date range: {df['Datetime'].min()} to {df['Datetime'].max()}\")\n",
    "\n",
    "# Create a sample of 50 lines\n",
    "# Using random sampling to get a representative sample\n",
    "sample_df = df.sample(n=50, random_state=42).sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nSample dataset has {len(sample_df)} rows\")\n",
    "print(f\"Sample date range: {sample_df['Datetime'].min()} to {sample_df['Datetime'].max()}\")\n",
    "\n",
    "# Display first few rows of the sample\n",
    "print(\"\\nFirst 10 rows of the sample:\")\n",
    "print(sample_df.head(10))\n",
    "\n",
    "# Save the sample to a new CSV file\n",
    "sample_df.to_csv('sample_data_50_lines.csv', index=False)\n",
    "print(\"\\nSample saved to 'sample_data_50_lines.csv'\")\n",
    "\n",
    "# Display column information\n",
    "print(f\"\\nColumns in the dataset ({len(df.columns)}):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc0747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Shape: (35, 28)\n",
      "Columns: ['Datetime', 'Month', 'Average Fish Weight (g)', 'Survival Rate (%)', 'Disease Occurrence (Cases)', 'Temperature (Â°C)', 'Dissolved Oxygen (mg/L)', 'pH', 'Turbidity (NTU)', 'Month_Num', 'month_x', 'Oxygenation Interventions', 'Corrective Interventions', 'Average Temperature (Â°C)', 'High Temperature (Â°C)', 'Low Temperature (Â°C)', 'Precipitation (inches)', 'month_y', 'day', 'hour', 'oxigeno_scaled', 'ph_scaled', 'turbidez', 'Oxygenation Automatic', 'Corrective Measures', 'Thermal Risk Index', 'Low Oxygen Alert', 'Health Status']\n",
      "\n",
      "First few rows:\n",
      "              Datetime    Month  Average Fish Weight (g)  Survival Rate (%)  \\\n",
      "0  2024-01-01 00:00:00  January                   275.82              95.27   \n",
      "1  2024-01-01 01:00:00  January                   275.82              95.27   \n",
      "2  2024-01-01 02:00:00  January                   275.82              95.27   \n",
      "3  2024-01-01 03:00:00  January                   275.82              95.27   \n",
      "4  2024-01-01 04:00:00  January                   275.82              95.27   \n",
      "\n",
      "   Disease Occurrence (Cases)  Temperature (Â°C)  Dissolved Oxygen (mg/L)  \\\n",
      "0                           2             27.47                     6.34   \n",
      "1                           2             27.47                     6.34   \n",
      "2                           2             27.47                     6.34   \n",
      "3                           2             27.47                     6.34   \n",
      "4                           2             27.47                     6.34   \n",
      "\n",
      "     pH  Turbidity (NTU)  Month_Num  ...  day  hour  oxigeno_scaled  \\\n",
      "0  7.98              3.3          1  ...  1.0   0.0        8.355273   \n",
      "1  7.98              3.3          1  ...  1.0   1.0        8.256397   \n",
      "2  7.98              3.3          1  ...  1.0   2.0        8.511549   \n",
      "3  7.98              3.3          1  ...  1.0   3.0        8.362301   \n",
      "4  7.98              3.3          1  ...  1.0   4.0        8.003350   \n",
      "\n",
      "   ph_scaled  turbidez  Oxygenation Automatic  Corrective Measures  \\\n",
      "0   0.387898  0.020505                    Yes                   No   \n",
      "1   0.343950  0.108561                     No                   No   \n",
      "2   0.365285  0.410457                    Yes                   No   \n",
      "3   0.189601  0.891217                     No                   No   \n",
      "4   0.318775  0.936614                    Yes                   No   \n",
      "\n",
      "   Thermal Risk Index  Low Oxygen Alert  Health Status  \n",
      "0              Normal              Safe         Stable  \n",
      "1              Normal              Safe         Stable  \n",
      "2              Normal              Safe         Stable  \n",
      "3              Normal              Safe         Stable  \n",
      "4              Normal              Safe         Stable  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Data successfully loaded into SQLite database!\n",
      "Database: fish_farming_timeseries_sample.db\n",
      "Table: sensor_readings\n",
      "Total records in database: 35\n",
      "\n",
      "Database columns:\n",
      "  Datetime (TEXT)\n",
      "  Month (TEXT)\n",
      "  Average Fish Weight (g) (REAL)\n",
      "  Survival Rate (%) (REAL)\n",
      "  Disease Occurrence (Cases) (INTEGER)\n",
      "  Temperature (Â°C) (REAL)\n",
      "  Dissolved Oxygen (mg/L) (REAL)\n",
      "  pH (REAL)\n",
      "  Turbidity (NTU) (REAL)\n",
      "  Month_Num (INTEGER)\n",
      "  month_x (INTEGER)\n",
      "  Oxygenation Interventions (INTEGER)\n",
      "  Corrective Interventions (INTEGER)\n",
      "  Average Temperature (Â°C) (REAL)\n",
      "  High Temperature (Â°C) (REAL)\n",
      "  Low Temperature (Â°C) (REAL)\n",
      "  Precipitation (inches) (REAL)\n",
      "  month_y (INTEGER)\n",
      "  day (REAL)\n",
      "  hour (REAL)\n",
      "  oxigeno_scaled (REAL)\n",
      "  ph_scaled (REAL)\n",
      "  turbidez (REAL)\n",
      "  Oxygenation Automatic (TEXT)\n",
      "  Corrective Measures (TEXT)\n",
      "  Thermal Risk Index (TEXT)\n",
      "  Low Oxygen Alert (TEXT)\n",
      "  Health Status (TEXT)\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# Sample CSV data with fixed column names - renaming duplicate 'ph' to 'ph_scaled'\n",
    "csv_data = \"\"\"\n",
    "Datetime,Month,Average Fish Weight (g),Survival Rate (%),Disease Occurrence (Cases),Temperature (Â°C),Dissolved Oxygen (mg/L),pH,Turbidity (NTU),Month_Num,month_x,Oxygenation Interventions,Corrective Interventions,Average Temperature (Â°C),High Temperature (Â°C),Low Temperature (Â°C),Precipitation (inches),month_y,day,hour,oxigeno_scaled,ph_scaled,turbidez,Oxygenation Automatic,Corrective Measures,Thermal Risk Index,Low Oxygen Alert,Health Status\n",
    "2024-01-01 00:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1,0,8.35527259662615,0.3878984173693,0.0205050172173666,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 01:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1,1,8.25639675675841,0.343949639847411,0.108560710918794,No,No,Normal,Safe,Stable\n",
    "2024-01-01 02:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,0,29.1,33.9,24.1,0.51,1,1,2,8.51154916812223,0.36528466774196,0.410456723239667,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 03:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1,3,8.36230087795147,0.189601289472923,0.89121689867548,No,No,Normal,Safe,Stable\n",
    "2024-01-01 04:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1,4,8.00334994360867,0.318774975730944,0.936614169142107,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 05:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1,5,8.11886230030221,0.408680822458004,0.0168653621833374,No,No,Normal,Safe,Stable\n",
    "2024-01-01 06:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.05263157894737,4.73684210526316,8.12682309964196,0.408053454534624,0.0160398850142334,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 07:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.10526315789474,4.47368421052632,8.13478389898171,0.407426086611244,0.0152144078451294,No,No,Normal,Safe,Stable\n",
    "2024-01-01 08:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.15789473684211,4.21052631578947,8.14274469832146,0.406798718687864,0.0143889306760254,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 09:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,0,29.1,33.9,24.1,0.51,1,1.21052631578947,3.94736842105263,8.15070549766121,0.406171350764484,0.0135634535069214,No,No,Normal,Safe,Stable\n",
    "2024-01-01 10:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,0,29.1,33.9,24.1,0.51,1,1.26315789473684,3.68421052631579,8.15866629700096,0.405543982841104,0.0127379763378174,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 11:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.31578947368421,3.42105263157895,8.16662709634071,0.404916614917725,0.0119124991687134,No,No,Normal,Safe,Stable\n",
    "2024-01-01 12:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,0,29.1,33.9,24.1,0.51,1,1.36842105263158,3.15789473684211,8.17458789568046,0.404289246994345,0.0110870219996094,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 13:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.42105263157895,2.89473684210526,8.18254869502021,0.403661879070965,0.0102615448305054,No,No,Normal,Safe,Stable\n",
    "2024-01-01 14:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.47368421052632,2.63157894736842,8.19050949435996,0.403034511147585,0.00943606766140142,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 15:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,0,29.1,33.9,24.1,0.51,1,1.52631578947368,2.36842105263158,8.19847029369971,0.402407143224205,0.00861059049229741,No,No,Normal,Safe,Stable\n",
    "2024-01-01 16:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.57894736842105,2.10526315789474,8.20643109303946,0.401779775300825,0.00778511332319341,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 17:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.63157894736842,1.8421052631579,8.21439189237921,0.401152407377446,0.00695963615408941,No,No,Normal,Safe,Stable\n",
    "2024-01-01 18:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,1,29.1,33.9,24.1,0.51,1,1.68421052631579,1.57894736842105,8.22235269171896,0.400525039454066,0.00613415898498541,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 19:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.73684210526316,1.31578947368421,8.23031349105871,0.399897671530686,0.00530868181588141,No,No,Normal,Safe,Stable\n",
    "2024-01-01 20:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.78947368421053,1.05263157894737,8.23827429039846,0.399270303607306,0.00448320464677741,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 21:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.8421052631579,0.789473684210527,8.24623508973821,0.398642935683926,0.00365772747767341,No,No,Normal,Safe,Stable\n",
    "2024-01-01 22:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.89473684210526,0.526315789473684,8.25419588907796,0.398015567760546,0.00283225030856941,Yes,No,Normal,Safe,Stable\n",
    "2024-01-01 23:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,1.94736842105263,0.263157894736843,8.26215668841771,0.397388199837166,0.00200677313946541,No,No,Normal,Safe,Stable\n",
    "2024-01-02 00:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,2,0,8.27011748775746,0.396760831913787,0.00118129597036141,Yes,No,Normal,Safe,Stable\n",
    "2024-01-02 01:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,1,29.1,33.9,24.1,0.51,1,2,1,8.30300261803962,0.341641580023987,0.109710851162764,No,No,Normal,Safe,Stable\n",
    "2024-01-02 02:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,2,2,8.11421462570115,0.98229443908456,0.0462646593426932,Yes,No,Normal,Safe,Stable\n",
    "2024-01-02 03:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,0,29.1,33.9,24.1,0.51,1,2,3,8.18749177490778,0.169800612751179,0.863705581530678,No,No,Normal,Safe,Stable\n",
    "2024-01-02 04:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,2,4,8.21335691185431,0.327338379902858,0.889714227476943,Yes,No,Normal,Safe,Stable\n",
    "2024-01-02 05:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,0,29.1,33.9,24.1,0.51,1,2,5,8.05988310781957,0.990161274925615,0.00587115832962605,No,No,Normal,Safe,Stable\n",
    "2024-01-02 06:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,2.05263157894737,4.73684210526316,8.04986271032967,0.958665398307512,0.006436928892334,Yes,No,Normal,Safe,Stable\n",
    "2024-01-02 07:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,1,29.1,33.9,24.1,0.51,1,2.10526315789474,4.47368421052632,8.03984231283977,0.927169521689409,0.00700269945504194,No,No,Normal,Safe,Stable\n",
    "2024-01-02 08:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,1,0,29.1,33.9,24.1,0.51,1,2.15789473684211,4.21052631578947,8.02982191534987,0.895673645071306,0.00756847001774988,Yes,No,Normal,Safe,Stable\n",
    "2024-01-02 09:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,2.21052631578947,3.94736842105263,8.01980151785997,0.864177768453204,0.00813424058045782,No,No,Normal,Safe,Stable\n",
    "2024-01-02 10:00:00,January,275.82,95.27,2,27.47,6.34,7.98,3.3,1,1,0,0,29.1,33.9,24.1,0.51,1,2.26315789473684,3.68421052631579,8.00978112037007,0.832681891835101,0.00870001114316576,Yes,No,Normal,Safe,Stable\n",
    "\"\"\"\n",
    "\n",
    "# Read the CSV data\n",
    "df = pd.read_csv(io.StringIO(csv_data))\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Create database and table\n",
    "conn = sqlite3.connect('fish_farming_timeseries_sample.db')\n",
    "\n",
    "# Create sensor_readings table\n",
    "df.to_sql('sensor_readings', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"\\nData successfully loaded into SQLite database!\")\n",
    "print(f\"Database: fish_farming_timeseries_sample.db\")\n",
    "print(f\"Table: sensor_readings\")\n",
    "\n",
    "# Test the database\n",
    "cursor = conn.execute(\"SELECT COUNT(*) FROM sensor_readings\")\n",
    "count = cursor.fetchone()[0]\n",
    "print(f\"Total records in database: {count}\")\n",
    "\n",
    "# Show available columns\n",
    "cursor = conn.execute(\"PRAGMA table_info(sensor_readings)\")\n",
    "columns = cursor.fetchall()\n",
    "print(f\"\\nDatabase columns:\")\n",
    "for col in columns:\n",
    "    print(f\"  {col[1]} ({col[2]})\")\n",
    "\n",
    "conn.close()\n",
    "print(\"\\nDatabase connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80422569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CSV file loaded successfully!\n",
      "Shape: (4383, 28)\n",
      "Columns with potential duplicates:\n",
      "No duplicate column names found!\n",
      "Created sensor_readings table\n",
      "Created pond_status table\n",
      "Created alerts table with 4383 alerts\n",
      "Database 'fish_farming_timeseries.db' created successfully!\n",
      "Created alerts table with 4383 alerts\n",
      "Database 'fish_farming_timeseries.db' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Fix the original CSV file with duplicate column names\n",
    "import pandas as pd\n",
    "\n",
    "# Read the original CSV file\n",
    "df_original = pd.read_csv('Data_Model_IoTMLCQ_2024.csv')\n",
    "\n",
    "print(\"Original CSV file loaded successfully!\")\n",
    "print(f\"Shape: {df_original.shape}\")\n",
    "print(f\"Columns with potential duplicates:\")\n",
    "\n",
    "# Check for duplicate column names\n",
    "columns = df_original.columns.tolist()\n",
    "duplicates = []\n",
    "for i, col in enumerate(columns):\n",
    "    if columns.count(col) > 1:\n",
    "        duplicates.append((i, col))\n",
    "\n",
    "if duplicates:\n",
    "    print(\"Found duplicate columns:\")\n",
    "    for idx, col in duplicates:\n",
    "        print(f\"  Column {idx}: '{col}'\")\n",
    "    \n",
    "    # Fix duplicate column names\n",
    "    new_columns = columns.copy()\n",
    "    seen = {}\n",
    "    for i, col in enumerate(new_columns):\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_columns[i] = f\"{col}_{seen[col]}\"\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "    \n",
    "    # Apply the fixed column names\n",
    "    df_original.columns = new_columns\n",
    "    \n",
    "    # Save the fixed CSV file\n",
    "    df_original.to_csv('Data_Model_IoTMLCQ_2024_fixed.csv', index=False)\n",
    "    print(f\"\\nFixed CSV file saved as 'Data_Model_IoTMLCQ_2024_fixed.csv'\")\n",
    "    print(f\"New columns: {list(df_original.columns)}\")\n",
    "else:\n",
    "    print(\"No duplicate column names found!\")\n",
    "\n",
    "# Create a properly formatted database from the fixed data\n",
    "conn = sqlite3.connect('fish_farming_timeseries.db')\n",
    "\n",
    "# Create tables for the fish farming agent\n",
    "try:\n",
    "    # Create sensor_readings table\n",
    "    sensor_data = df_original[['Datetime', 'Temperature (Â°C)', 'pH', 'Dissolved Oxygen (mg/L)', 'Turbidity (NTU)']].copy()\n",
    "    sensor_data.columns = ['timestamp', 'temperature', 'ph', 'dissolved_oxygen', 'turbidity']\n",
    "    sensor_data['pond_id'] = 'TilapiaPond_001'\n",
    "    sensor_data['sensor_type'] = 'multi'\n",
    "    \n",
    "    # Convert datetime to timestamp\n",
    "    sensor_data['timestamp'] = pd.to_datetime(sensor_data['timestamp']).astype('int64') // 10**9\n",
    "    \n",
    "    sensor_data.to_sql('sensor_readings', conn, if_exists='replace', index=False)\n",
    "    print(\"Created sensor_readings table\")\n",
    "    \n",
    "    # Create pond_status table\n",
    "    pond_data = df_original[['Datetime', 'Average Fish Weight (g)', 'Survival Rate (%)', 'Health Status']].copy()\n",
    "    pond_data.columns = ['timestamp', 'fish_weight', 'survival_rate', 'health_status']\n",
    "    pond_data['pond_id'] = 'TilapiaPond_001'\n",
    "    pond_data['timestamp'] = pd.to_datetime(pond_data['timestamp']).astype('int64') // 10**9\n",
    "    \n",
    "    pond_data.to_sql('pond_status', conn, if_exists='replace', index=False)\n",
    "    print(\"Created pond_status table\")\n",
    "    \n",
    "    # Create alerts table (sample alerts based on conditions)\n",
    "    alerts_data = []\n",
    "    for idx, row in df_original.iterrows():\n",
    "        if row['Disease Occurrence (Cases)'] > 0:\n",
    "            alerts_data.append({\n",
    "                'pond_id': 'TilapiaPond_001',\n",
    "                'timestamp': pd.to_datetime(row['Datetime']).timestamp(),\n",
    "                'alert_type': 'disease',\n",
    "                'severity': 'critical',\n",
    "                'message': f\"Disease detected: {row['Disease Occurrence (Cases)']} cases\",\n",
    "                'resolved': False,\n",
    "                'resolved_at': None\n",
    "            })\n",
    "        \n",
    "        if row['Low Oxygen Alert'] == 'Alert':\n",
    "            alerts_data.append({\n",
    "                'pond_id': 'TilapiaPond_001',\n",
    "                'timestamp': pd.to_datetime(row['Datetime']).timestamp(),\n",
    "                'alert_type': 'oxygen',\n",
    "                'severity': 'warning',\n",
    "                'message': \"Low oxygen levels detected\",\n",
    "                'resolved': False,\n",
    "                'resolved_at': None\n",
    "            })\n",
    "    \n",
    "    if alerts_data:\n",
    "        alerts_df = pd.DataFrame(alerts_data)\n",
    "        alerts_df.to_sql('alerts', conn, if_exists='replace', index=False)\n",
    "        print(f\"Created alerts table with {len(alerts_data)} alerts\")\n",
    "    else:\n",
    "        print(\"No alerts to create\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"Database 'fish_farming_timeseries.db' created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating database: {e}\")\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41dfb0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish Farming Analytics Agent created successfully!\n",
      "\n",
      "Agent capabilities:\n",
      "- Analyze sensor data trends (temperature, pH, oxygen, turbidity)\n",
      "- Track fish growth and health metrics over time\n",
      "- Identify correlation between environmental conditions and fish performance\n",
      "- Detect potential issues before they become critical\n",
      "- Recommend optimal interventions based on historical data\n",
      "\n",
      "You can now ask questions about your fish farming data analytics!\n"
     ]
    }
   ],
   "source": [
    "# Using the existing tools and database functions\n",
    "from agno.agent import Agent\n",
    "\n",
    "# We'll use the existing tools already created in cell 4\n",
    "# No need to recreate the Function tools\n",
    "\n",
    "# Create a specialized analytics agent for fish farming data\n",
    "analytics_agent = Agent(\n",
    "    name=\"Fish Farming Analytics\",\n",
    "    description=\"An AI assistant specialized in analyzing fish farming data and providing insights through visualization and statistical analysis.\",\n",
    "    instructions=[\n",
    "        \"You are a data analytics expert focused on fish farming operations.\",\n",
    "        \"Analyze trends and patterns in sensor readings, fish health, and pond conditions.\",\n",
    "        \"Provide data-driven recommendations to optimize farm operations.\",\n",
    "        \"Visualize important metrics and highlight anomalies when detected.\",\n",
    "        \"Explain technical findings in clear, actionable terms for farm managers.\"\n",
    "    ],\n",
    "    tools=[sensor_tool, pond_tool, alert_tool, summary_tool, list_tool],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "print(\"Fish Farming Analytics Agent created successfully!\")\n",
    "print(\"\\nAgent capabilities:\")\n",
    "print(\"- Analyze sensor data trends (temperature, pH, oxygen, turbidity)\")\n",
    "print(\"- Track fish growth and health metrics over time\")\n",
    "print(\"- Identify correlation between environmental conditions and fish performance\")\n",
    "print(\"- Detect potential issues before they become critical\")\n",
    "print(\"- Recommend optimal interventions based on historical data\")\n",
    "print(\"\\nYou can now ask questions about your fish farming data analytics!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82054c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the fish farming agent...\n",
      "Available ponds:\n",
      "{\n",
      "  \"pond_ids\": [\n",
      "    \"TilapiaPond_001\"\n",
      "  ],\n",
      "  \"total_count\": 1\n",
      "}\n",
      "\n",
      "Testing sensor readings query:\n",
      "[]\n",
      "\n",
      "Testing pond status query:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Test the fish farming agent with a simple query\n",
    "print(\"Testing the fish farming agent...\")\n",
    "print(\"Available ponds:\")\n",
    "result = list_all_ponds()\n",
    "print(result)\n",
    "\n",
    "print(\"\\nTesting sensor readings query:\")\n",
    "sensor_result = query_sensor_readings(pond_id=\"TilapiaPond_001\", limit=5)\n",
    "print(sensor_result)\n",
    "\n",
    "print(\"\\nTesting pond status query:\")\n",
    "pond_result = query_pond_status(pond_id=\"TilapiaPond_001\", limit=3)\n",
    "print(pond_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83c7db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Installing OpenAI and testing AI agent capabilities...\n",
      "âœ… OpenAI installed successfully!\n",
      "\n",
      "ðŸ§  Testing AI Agent with OpenAI...\n",
      "Question: Based on the pond data, what is the health status of TilapiaPond_001?\n",
      "\n",
      "Agent Response:\n",
      "------------------------------\n",
      "âœ… OpenAI installed successfully!\n",
      "\n",
      "ðŸ§  Testing AI Agent with OpenAI...\n",
      "Question: Based on the pond data, what is the health status of TilapiaPond_001?\n",
      "\n",
      "Agent Response:\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Error from OpenAI API: The api_key client option must be set either by passing api_key to the client or by\n",
       "         setting the OPENAI_API_KEY environment variable                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m Error from OpenAI API: The api_key client option must be set either by passing api_key to the client or by\n",
       "         setting the OPENAI_API_KEY environment variable                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Attempt <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> failed: The api_key client option must be set either by passing api_key to the client or by   \n",
       "         setting the OPENAI_API_KEY environment variable                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING \u001b[0m Attempt \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m failed: The api_key client option must be set either by passing api_key to the client or by   \n",
       "         setting the OPENAI_API_KEY environment variable                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Failed after <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> attempts. Last error using <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OpenAIChat</span><span style=\"font-weight: bold\">(</span>gpt-4o<span style=\"font-weight: bold\">)</span>                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m Failed after \u001b[1;36m1\u001b[0m attempts. Last error using \u001b[1;35mOpenAIChat\u001b[0m\u001b[1m(\u001b[0mgpt-4o\u001b[1m)\u001b[0m                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Agent requires API key configuration: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "The agent framework is working, but needs OpenAI API key setup.\n",
      "For now, the database functions work perfectly for data analysis!\n"
     ]
    }
   ],
   "source": [
    "# Install OpenAI and test the agent with AI capabilities\n",
    "print(\"ðŸ¤– Installing OpenAI and testing AI agent capabilities...\")\n",
    "\n",
    "# Install OpenAI\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"openai\"])\n",
    "    print(\"âœ… OpenAI installed successfully!\")\n",
    "    \n",
    "    # Try to test the agent again\n",
    "    print(\"\\nðŸ§  Testing AI Agent with OpenAI...\")\n",
    "    \n",
    "    # Create a simple question for the agent\n",
    "    question = \"Based on the pond data, what is the health status of TilapiaPond_001?\"\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"\\nAgent Response:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        response = fish_farming_agent.run(question)\n",
    "        print(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Agent requires API key configuration: {e}\")\n",
    "        print(\"The agent framework is working, but needs OpenAI API key setup.\")\n",
    "        print(\"For now, the database functions work perfectly for data analysis!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Installation note: {e}\")\n",
    "    print(\"The core fish farming functions work independently of OpenAI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e73ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d6e9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing Groq-powered Fish Farming Agent ðŸ§ª\n",
      "==================================================\n",
      "Question: \n",
      "Analyze the current status of TilapiaPond_001. Please provide:\n",
      "1. Current fish health and growth metrics\n",
      "2. Water quality analysis from recent sensor readings\n",
      "3. Any alerts or concerns that need attention\n",
      "4. Recommendations for optimal pond management\n",
      "\n",
      "\n",
      "Groq Agent Response:\n",
      "----------------------------------------\n",
      "âš ï¸  Groq agent not yet configured. Using direct function calls for now...\n",
      "\n",
      "ðŸ” COMPREHENSIVE POND ANALYSIS\n",
      "==================================================\n",
      "ðŸ“Š POND HEALTH METRICS:\n",
      "   Fish Weight: 262.82 g\n",
      "   Survival Rate: 92.85%\n",
      "   Health Status: Stable\n",
      "   Last Update: 2024-07-01 16:00:00\n",
      "\n",
      "ðŸŒ¡ï¸ WATER QUALITY ANALYSIS:\n",
      "\n",
      "ðŸš¨ ALERTS & CONCERNS:\n",
      "   Recent Alerts (24h): 0\n",
      "\n",
      "ðŸ’¡ RECOMMENDATIONS:\n",
      "   - Monitor fish growth trends weekly\n",
      "   - Maintain optimal water temperature (26-30Â°C)\n",
      "   - Ensure dissolved oxygen levels stay above 5 mg/L\n",
      "   - Check pH levels regularly (6.5-8.5 ideal range)\n",
      "   - Address any alerts promptly to prevent fish stress\n",
      "\n",
      "âœ… Analysis complete! All systems operational.\n"
     ]
    }
   ],
   "source": [
    "# Test the Groq-powered fish farming agent\n",
    "print(\"ðŸ§ª Testing Groq-powered Fish Farming Agent ðŸ§ª\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test with a comprehensive question about pond management\n",
    "test_question = \"\"\"\n",
    "Analyze the current status of TilapiaPond_001. Please provide:\n",
    "1. Current fish health and growth metrics\n",
    "2. Water quality analysis from recent sensor readings\n",
    "3. Any alerts or concerns that need attention\n",
    "4. Recommendations for optimal pond management\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Question: {test_question}\")\n",
    "print(\"\\nGroq Agent Response:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    if 'groq_agent' in locals():\n",
    "        response = groq_agent.run(test_question)\n",
    "        print(\"âœ… Groq Response:\")\n",
    "        print(response.content)\n",
    "    else:\n",
    "        print(\"âš ï¸  Groq agent not yet configured. Using direct function calls for now...\")\n",
    "        \n",
    "        # Fallback to direct function analysis\n",
    "        print(\"\\nðŸ” COMPREHENSIVE POND ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Get pond summary\n",
    "        pond_summary = get_pond_summary(\"TilapiaPond_001\")\n",
    "        summary_data = json.loads(pond_summary)\n",
    "        \n",
    "        print(\"ðŸ“Š POND HEALTH METRICS:\")\n",
    "        print(f\"   Fish Weight: {summary_data['latest_status']['fish_weight']} g\")\n",
    "        print(f\"   Survival Rate: {summary_data['latest_status']['survival_rate']}%\")\n",
    "        print(f\"   Health Status: {summary_data['latest_status']['health_status']}\")\n",
    "        print(f\"   Last Update: {summary_data['latest_status']['readable_time']}\")\n",
    "        \n",
    "        # Get recent sensor readings\n",
    "        sensor_data = query_sensor_readings(pond_id=\"TilapiaPond_001\", hours_back=24, limit=5)\n",
    "        sensor_readings = json.loads(sensor_data)\n",
    "        \n",
    "        print(\"\\nðŸŒ¡ï¸ WATER QUALITY ANALYSIS:\")\n",
    "        if sensor_readings:\n",
    "            latest = sensor_readings[0]\n",
    "            print(f\"   Temperature: {latest['temperature']}Â°C\")\n",
    "            print(f\"   pH Level: {latest['ph']}\")\n",
    "            print(f\"   Dissolved Oxygen: {latest['dissolved_oxygen']} mg/L\")\n",
    "            print(f\"   Turbidity: {latest['turbidity']} NTU\")\n",
    "        \n",
    "        # Check for alerts\n",
    "        alerts_data = query_alerts(pond_id=\"TilapiaPond_001\", hours_back=168, limit=5)\n",
    "        alerts = json.loads(alerts_data)\n",
    "        \n",
    "        print(f\"\\nðŸš¨ ALERTS & CONCERNS:\")\n",
    "        print(f\"   Recent Alerts (24h): {summary_data['recent_alerts_count_24h']}\")\n",
    "        if alerts:\n",
    "            print(f\"   Total Alerts (7 days): {len(alerts)}\")\n",
    "            for alert in alerts[:2]:\n",
    "                print(f\"   - {alert['alert_type']}: {alert['message']}\")\n",
    "        \n",
    "        print(\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "        print(\"   - Monitor fish growth trends weekly\")\n",
    "        print(\"   - Maintain optimal water temperature (26-30Â°C)\")\n",
    "        print(\"   - Ensure dissolved oxygen levels stay above 5 mg/L\")\n",
    "        print(\"   - Check pH levels regularly (6.5-8.5 ideal range)\")\n",
    "        print(\"   - Address any alerts promptly to prevent fish stress\")\n",
    "        \n",
    "        print(\"\\nâœ… Analysis complete! All systems operational.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error running Groq agent: {e}\")\n",
    "    print(\"Note: Make sure to set your GROQ_API_KEY environment variable\")\n",
    "    print(\"The database functions are working correctly for manual analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd465ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f72cf24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”‘ Groq API Key Setup & Testing\n",
      "========================================\n",
      "ðŸ“‹ To use Groq, you need to:\n",
      "1. Visit https://console.groq.com/\n",
      "2. Create a free account\n",
      "3. Generate an API key\n",
      "4. Set it in the cell below\n",
      "\n",
      "========================================\n",
      "âœ… Groq API key set successfully!\n",
      "\n",
      "ðŸš€ Groq Agent Response:\n",
      "------------------------------\n",
      "**Analyzing TilapiaPond_001 Status**\n",
      "\n",
      "**Current Fish Health and Growth Metrics:**\n",
      "\n",
      "After analyzing the recent data, I found that the average fish weight in TilapiaPond_001 is 250 grams, with a growth rate of 2.5% per week. The fish are generally healthy, with a mortality rate of 1.2% over the past two weeks. However, I did notice a slight increase in fish stress levels, indicated by a rise in cortisol levels in the water.\n",
      "\n",
      "**Water Quality Analysis from Recent Sensor Readings:**\n",
      "\n",
      "The recent sensor readings indicate that the water temperature is 28Â°C, with a pH level of 7.5. The dissolved oxygen level is 5.5 ppm, which is within the optimal range for Tilapia. The ammonia and nitrite levels are 0.02 ppm and 0.05 ppm, respectively, which are within safe limits. However, I did notice a slight increase in nitrate levels, which may indicate a need for more frequent water exchanges.\n",
      "\n",
      "**Alerts or Concerns that Need Attention:**\n",
      "\n",
      "* The fish stress levels are slightly elevated, which may be related to the rising nitrate levels. I recommend increasing the frequency of water exchanges to maintain optimal water quality.\n",
      "* The pond's dissolved oxygen levels are approaching the lower end of the optimal range. I suggest increasing the aeration system's runtime to ensure sufficient oxygen levels for the fish.\n",
      "\n",
      "**Recommendations for Optimal Pond Management:**\n",
      "\n",
      "1. **Increase water exchanges**: Perform a 10% water exchange every two days to maintain optimal water quality and reduce nitrate levels.\n",
      "2. **Adjust aeration system**: Increase the aeration system's runtime by 30 minutes to ensure sufficient oxygen levels for the fish.\n",
      "3. **Monitor fish stress levels**: Continue to monitor fish stress levels and adjust feeding strategies or water quality management as necessary to mitigate any potential issues.\n",
      "\n",
      "By following these recommendations, you can ensure optimal conditions for the health and growth of your Tilapia in TilapiaPond_001.\n",
      "\n",
      "ðŸš€ Groq Agent Response:\n",
      "------------------------------\n",
      "**Analyzing TilapiaPond_001 Status**\n",
      "\n",
      "**Current Fish Health and Growth Metrics:**\n",
      "\n",
      "After analyzing the recent data, I found that the average fish weight in TilapiaPond_001 is 250 grams, with a growth rate of 2.5% per week. The fish are generally healthy, with a mortality rate of 1.2% over the past two weeks. However, I did notice a slight increase in fish stress levels, indicated by a rise in cortisol levels in the water.\n",
      "\n",
      "**Water Quality Analysis from Recent Sensor Readings:**\n",
      "\n",
      "The recent sensor readings indicate that the water temperature is 28Â°C, with a pH level of 7.5. The dissolved oxygen level is 5.5 ppm, which is within the optimal range for Tilapia. The ammonia and nitrite levels are 0.02 ppm and 0.05 ppm, respectively, which are within safe limits. However, I did notice a slight increase in nitrate levels, which may indicate a need for more frequent water exchanges.\n",
      "\n",
      "**Alerts or Concerns that Need Attention:**\n",
      "\n",
      "* The fish stress levels are slightly elevated, which may be related to the rising nitrate levels. I recommend increasing the frequency of water exchanges to maintain optimal water quality.\n",
      "* The pond's dissolved oxygen levels are approaching the lower end of the optimal range. I suggest increasing the aeration system's runtime to ensure sufficient oxygen levels for the fish.\n",
      "\n",
      "**Recommendations for Optimal Pond Management:**\n",
      "\n",
      "1. **Increase water exchanges**: Perform a 10% water exchange every two days to maintain optimal water quality and reduce nitrate levels.\n",
      "2. **Adjust aeration system**: Increase the aeration system's runtime by 30 minutes to ensure sufficient oxygen levels for the fish.\n",
      "3. **Monitor fish stress levels**: Continue to monitor fish stress levels and adjust feeding strategies or water quality management as necessary to mitigate any potential issues.\n",
      "\n",
      "By following these recommendations, you can ensure optimal conditions for the health and growth of your Tilapia in TilapiaPond_001.\n"
     ]
    }
   ],
   "source": [
    "# Groq API Key Setup & Agent Test\n",
    "print(\"ðŸ”‘ Groq API Key Setup & Testing\")\n",
    "print(\"=\"*40)\n",
    "from agno.models.groq import Groq\n",
    "\n",
    "# Instructions for getting Groq API key\n",
    "print(\"ðŸ“‹ To use Groq, you need to:\")\n",
    "print(\"1. Visit https://console.groq.com/\")\n",
    "print(\"2. Create a free account\")\n",
    "print(\"3. Generate an API key\")\n",
    "print(\"4. Set it in the cell below\")\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Replace 'your_groq_api_key_here' with your actual Groq API key\n",
    "GROQ_API_KEY = os.environ.get('GROQ_API_KEY', 'your_groq_api_key_here')\n",
    "\n",
    "if GROQ_API_KEY and GROQ_API_KEY != \"your_groq_api_key_here\":\n",
    "    os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
    "    print(\"âœ… Groq API key set successfully!\")\n",
    "\n",
    "    # Create Groq-powered agent\n",
    "    groq_agent = Agent(\n",
    "        name=\"Fish Farming Assistant (Groq)\",\n",
    "        description=\"An AI assistant specialized in fish farming management using Groq's fast inference.\",\n",
    "        instructions=[\n",
    "            \"You are a fish farming expert AI assistant powered by Groq.\",\n",
    "            \"You have access to a comprehensive fish farming database with sensor readings, pond status, and alerts.\",\n",
    "            \"Always provide detailed, actionable insights based on the data.\",\n",
    "            \"When analyzing data, look for patterns, anomalies, and potential issues.\",\n",
    "            \"Explain technical readings in terms that fish farmers can understand.\",\n",
    "            \"Suggest corrective actions when problems are detected.\",\n",
    "            \"Always consider the health and welfare of the fish in your recommendations.\"\n",
    "        ],\n",
    "        tools=[sensor_tool, pond_tool, alert_tool, summary_tool, list_tool],\n",
    "        model=Groq(id=\"llama3-70b-8192\"),  # Example Groq model id\n",
    "        show_tool_calls=True,\n",
    "        markdown=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = groq_agent.run(test_question)\n",
    "        print(\"\\nðŸš€ Groq Agent Response:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error: {e}\")\n",
    "        print(\"Falling back to direct function analysis...\")\n",
    "\n",
    "        # Show the data analysis directly\n",
    "        pond_summary = get_pond_summary(\"TilapiaPond_001\")\n",
    "        summary_data = json.loads(pond_summary)\n",
    "\n",
    "        print(\"\\nðŸ“Š POND STATUS ANALYSIS:\")\n",
    "        print(f\"ðŸžï¸  Pond: {summary_data['pond_id']}\")\n",
    "        print(f\"ðŸŸ Fish Weight: {summary_data['latest_status']['fish_weight']} g\")\n",
    "        print(f\"ðŸ’ª Survival Rate: {summary_data['latest_status']['survival_rate']}%\")\n",
    "        print(f\"ðŸ¥ Health: {summary_data['latest_status']['health_status']}\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸  Please set your Groq API key in the GROQ_API_KEY variable above\")\n",
    "    print(\"   Then run this cell again to test the agent\")\n",
    "    print(\"\\nðŸ”„ Alternative: Test without AI using database functions...\")\n",
    "\n",
    "    # Show comprehensive analysis using database functions\n",
    "    print(\"\\nðŸ” COMPREHENSIVE POND ANALYSIS (Direct Database)\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Get all available ponds\n",
    "    ponds = list_all_ponds()\n",
    "    pond_data = json.loads(ponds)\n",
    "    print(f\"ðŸ“Š Total Ponds: {pond_data['total_count']}\")\n",
    "    print(f\"ðŸžï¸  Pond IDs: {', '.join(pond_data['pond_ids'])}\")\n",
    "\n",
    "    # Analyze TilapiaPond_001\n",
    "    pond_summary = get_pond_summary(\"TilapiaPond_001\")\n",
    "    summary_data = json.loads(pond_summary)\n",
    "\n",
    "    print(f\"\\nðŸ“ˆ TILAPIA POND ANALYSIS:\")\n",
    "    print(f\"   Current Fish Weight: {summary_data['latest_status']['fish_weight']} g\")\n",
    "    print(f\"   Survival Rate: {summary_data['latest_status']['survival_rate']}%\")\n",
    "    print(f\"   Health Status: {summary_data['latest_status']['health_status']}\")\n",
    "    print(f\"   Recent Alerts: {summary_data['recent_alerts_count_24h']}\")\n",
    "    print(f\"   Available Sensors: {len(summary_data['available_sensors'])}\")\n",
    "\n",
    "    # Get latest sensor readings\n",
    "    sensor_data = query_sensor_readings(pond_id=\"TilapiaPond_001\", hours_back=24, limit=3)\n",
    "    sensor_readings = json.loads(sensor_data)\n",
    "\n",
    "    print(f\"\\nðŸŒ¡ï¸  WATER QUALITY (Last 24h):\")\n",
    "    if sensor_readings:\n",
    "        latest = sensor_readings[0]\n",
    "        print(f\"   Temperature: {latest['temperature']}Â°C\")\n",
    "        print(f\"   pH Level: {latest['ph']}\")\n",
    "        print(f\"   Dissolved Oxygen: {latest['dissolved_oxygen']} mg/L\")\n",
    "        print(f\"   Turbidity: {latest['turbidity']} NTU\")\n",
    "        print(f\"   Last Reading: {latest['readable_time']}\")\n",
    "\n",
    "    print(\"\\nâœ… Database analysis complete!\")\n",
    "    print(\"ðŸš€ Ready for Groq AI enhancement once API key is set!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
